\section{Programming tracter}

The general idea is that the application programmer should be able to
write modules easily and not worry about the data flow.  So

\begin{itemize}
\item It should be easy to write new modules.  Just one or two methods
  need to be written.
\item It should be easy to incorporate new modules into a signal
  processing chain.
\item It should be easy to get configuration parameters into new
  modules.
\end{itemize}
However, there is one (at least one...) slight difficulty:
\begin{itemize}
\item The programmer has to know that he is reading from and writing
  to circular buffers.
\end{itemize}

This is not a difficult concept.  It's just different from the usual
model where input and output data tend to be in linear contiguous
storage.

To cover these issues by example, first consider the top level
routine.  At the top level, plugins must be joined together to form a
graph.  For instance, here is a simple ASR front-end:
\begin{verbatim}
    // Raw file source and normaliser for 16 bit big endian files
    FileSource<short>* source = new FileSource<short>();
    Normalise* n = new Normalise(source);

    // Signal processing chain
    ZeroFilter* zf = new ZeroFilter(n);
    Periodogram* p = new Periodogram(zf);
    MelFilter* mf = new MelFilter(p);
    Cepstrum* c = new Cepstrum(mf);

    // An HTK file sink
    HTKSink sink(c);
\end{verbatim}
A few points should be self-explanatory:
\begin{itemize}
\item We need a source.  In this case it's a file.
\item We need a sink.  In this case it is also related to a file - it
  will write out an HTK format parameter file.
\item Plugins can be arbitrarily chained together between the source
  and the sink.
\end{itemize}
These, however, are more subtle:
\begin{itemize}
\item All the FileSource really does is memory map a file (specified
  later).  In general, the file will be 2 byte integer format and may
  require byte swapping.  The Normalise plugin is required to byte
  swap if necessary, and to convert to floating point format.  Unless
  otherwise specified, audio samples are scaled to lie between -1.0
  and +1.0.
\item All plugins except the sink are allocated with new.  The sink is
  on the stack in this case.  This means that the sink will be
  destroyed with the containing class.  The other plugins will be
  recursively destroyed by the sink destructor.
\end{itemize}

Inside the plugin, when data is requested by a downstream plugin, the
tracter framework will first check the cache for a previous result.
If the result does not exist, it will fetch the data.  The programmer
hence has to implement the algorithm as a cache fetch.

A fetch routine looks something like this:
\begin{verbatim}
bool Example::UnaryFetch(IndexType iIndex, int iOffset)
{
    assert(iIndex >= 0);

    // Read the input frame
    CacheArea inputArea;
    int count = mInput->Read(inputArea, iIndex);
    if (count < 1)
        return false;

    // Get pointers to the input and output data
    float* p = mInput->GetPointer(inputArea.offset);
    float* cache = GetPointer(iOffset);

    // Do some processing
    for (int i=0; i<mArraySize; i++)
        cache[i] = some_function_of(p);

    return true;
}
\end{verbatim}

Notice a few more points:
\begin{itemize}
\item The UnaryFetch() routine passes in the offset from the beginning
  of a circular buffer.  This must be converted to a pointer to be of
  use.
\item If the request to the input plugin fails, the failure is passed
  forward to the calling plugin.  This process indicates the end of
  available input data (e.g., end of file).
\item The variable mArraySize is defined in all plugins.  It allows
  the one dimensional cache to store two dimensional data, e.g.
  sequences of spectra rather than just sequences of samples.
\end{itemize}

\subsection{Tracter and the Standard Template Library}

\subsubsection{Rationale}

I come from an embedded programming background where the STL is
regarded as fundamentally evil.  This is because new chips always have
a C compiler, tend to have a C++ compiler, but tend not to support all
of C++.  That, and the STL took a long time to stabilise on gcc.

That said, the STL now seems to be pretty stable, and tracter is aimed
at linux boxes rather than embedded chips.  So tracter uses the STL to
some extent.

For people who have just tuned in, the STL has 3 levels:
\begin{itemize}
\item Containers like vectors and associative arrays.
\item Iterators, that serve to obfuscate these containers by making
  the interfaces all the same.
\item Algorithms, like sorting and searching, that use the iterator
  interface and hence don't care about the container type.
\end{itemize}

My feeling about the STL currently is that programmers (read: I) tend
to like to know exactly what the underlying data structure is.  In
turn, they have a feeling for what the natural iterator is.  For
instance, an array is fundamentally just a contiguous area of memory
and the natural iterator is an integer.  A list is bunch of things
joined by pointers and the natural iterator is a pointer.  Using the
natural iterator makes the code more readable.  If you want to use a
sort or search, get an STL iterator from the container and pass it to
the sort.

Another, little acknowledged, advantage of the containers is that they
specify an allocator that is much more flexible than new and delete.
The STL allocator distinguishes the allocated size from the size of
the container.  This means that the container can grow (and shrink)
efficiently.

Anyway, the above is just an explanation of why the parts I wrote are
the way they are.  All that aside, please use tracter in that way that
you want to use it.  I don't mean to impose any particular programming
style.

\section{Examples}

The plugin caches are currently std::vector<float>.

%%% Local Variables: 
%%% mode: latex
%%% TeX-PDF-mode: t
%%% TeX-master: "tracter"
%%% End: 
