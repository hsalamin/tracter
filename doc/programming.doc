/**
\page programming Programming tracter

The general idea is that the application programmer should be able to
write modules easily and not worry about the data flow.  So

- It should be easy to write new modules.  Just one or two methods
  need to be written.

- It should be easy to incorporate new modules into a signal
  processing chain.

- It should be easy to get configuration parameters into new modules.

However, there is one (at least one...) slight difficulty:

- The programmer has to know that he is reading from and writing to
  circular buffers.

This is not a difficult concept.  It's just different from the usual
model where input and output data tend to be in linear contiguous
storage.

To cover these issues by example, first consider the top level
routine.  At the top level, plugins must be joined together to form a
graph.  For instance, here is a simple ASR front-end:
\code
    // Raw file source and normaliser for 16 bit big endian files
    FileSource<short>* source = new FileSource<short>();
    Normalise* n = new Normalise(source);

    // Signal processing chain
    ZeroFilter* zf = new ZeroFilter(n);
    Periodogram* p = new Periodogram(zf);
    MelFilter* mf = new MelFilter(p);
    Cepstrum* c = new Cepstrum(mf);

    // An HTK file sink
    HTKSink sink(c);
\endcode
A few points should be self-explanatory:

- We need a source.  In this case it's a file.

- We need a sink.  In this case it is also related to a file - it will
  write out an HTK format parameter file.

- Plugins can be arbitrarily chained together between the source and
  the sink.

These, however, are more subtle:

- All the FileSource really does is memory map a file (specified
later).  In general, the file will be 2 byte integer format and may
require byte swapping.  The Normalise plugin is required to byte swap
if necessary, and to convert to floating point format.  Unless
otherwise specified, audio samples are scaled to lie between -1.0 and
+1.0.

- All plugins except the sink are allocated with new.  The sink is on
the stack in this case.  This means that the sink will be destroyed
with the containing class.  The other plugins will be recursively
destroyed by the sink destructor.

Inside the plugin, when data is requested by a downstream plugin, the
tracter framework will first check the cache for a previous result.
If the result does not exist, it will fetch the data.  The programmer
hence has to implement the algorithm as a cache fetch.

A fetch routine looks something like this:
\code
bool Example::UnaryFetch(IndexType iIndex, int iOffset)
{
    assert(iIndex >= 0);

    // Read the input frame
    CacheArea inputArea;
    int count = mInput->Read(inputArea, iIndex);
    if (count < 1)
        return false;

    // Get pointers to the input and output data
    float* p = mInput->GetPointer(inputArea.offset);
    float* cache = GetPointer(iOffset);

    // Do some processing
    for (int i=0; i<mArraySize; i++)
        cache[i] = some_function_of(p);

    return true;
}
\endcode

Notice a few more points:

- The UnaryFetch() routine passes in the offset from the beginning of
  a circular buffer.  This must be converted to a pointer to be of
  use.

- If the request to the input plugin fails, the failure is passed
  forward to the calling plugin.  This process indicates the end of
  available input data (e.g., end of file).

- The variable mArraySize is defined in all plugins.  It allows the
  one dimensional cache to store two dimensional data, e.g. sequences
  of spectra rather than just sequences of samples.
*/
